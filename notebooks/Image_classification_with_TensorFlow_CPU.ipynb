{"cells": [{"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "N6ZDpd9XzFeN"}, "source": ["# Image classification with TensorFlow \n", "\n", "Based on an original notebook by the TensorFlow authors, licensed under Apache 2.0.\n", "\n", "Use **Shift + Enter** to run the cells. When prompted, click **Run anyway** then **Yes**. Try it on this cell..."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "RNo1Vfghpa8j"}, "source": ["## Overview\n", "\n", "In this notebook, we're going to classify some images of fossils... in fewer than 80 lines of code.\n", "\n", "A 'notebook' is an interactive coding and note-taking environment. We're going to be using some cutting edge technology, right in your browser. We will see:\n", "\n", "- A deep neural network in action.\n", "- Google's TensorFlow deep learning library.\n", "\n", "There are fewer than 80 lines of code altogether."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Lvo0t7XVIkWZ"}, "source": ["## Load the data"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "MICrRv8rmXVq"}, "source": ["We'll begin by downloading the dataset. Run this cell:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 34}, "colab_type": "code", "id": "i9aTiz206S68", "outputId": "30548b10-656d-4454-f598-6c4db1ddb453"}, "outputs": [], "source": ["import requests\n", "import numpy as np\n", "from io import BytesIO\n", "\n", "X_ = requests.get(\"https://s3.amazonaws.com/agilegeo/geocomp/image_X.npy\")\n", "y_ = requests.get(\"https://s3.amazonaws.com/agilegeo/geocomp/integer_y.npy\")\n", "\n", "X = np.load(BytesIO(X_.content))\n", "y = np.load(BytesIO(y_.content))\n", "\n", "print(\"Data loaded!\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 136}, "colab_type": "code", "id": "Rupu_61y6tt7", "outputId": "0bda8ed7-1a07-40d8-a816-5b8c206a579d"}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=186)\n", "\n", "X_val.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "\n", "plt.imshow(X_train[0, :, :, 0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_val"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Shallow learning model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train.shape, X_val.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.svm import SVC\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluating the model, we see that we got about 60% accuracy:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Hgc2FZKVMx15"}, "source": ["## Deep learning model\n", "\n", "The following example uses a standard conv-net that has 3 layers with drop-out and batch normalization between each layer."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 870}, "colab_type": "code", "id": "W7gMbs70GxA7", "outputId": "85ad01a0-fa03-4869-850c-2203faede85b"}, "outputs": [], "source": ["import tensorflow as tf\n", "\n", "model = tf.keras.models.Sequential()\n", "\n", "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n", "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n", "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n", "model.add(tf.keras.layers.Dropout(0.25))\n", "\n", "model.add(tf.keras.layers.BatchNormalization())\n", "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n", "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n", "model.add(tf.keras.layers.Dropout(0.25))\n", "\n", "model.add(tf.keras.layers.BatchNormalization())\n", "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n", "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n", "model.add(tf.keras.layers.Dropout(0.25))\n", "\n", "model.add(tf.keras.layers.Flatten())\n", "\n", "model.add(tf.keras.layers.Dense(32))\n", "model.add(tf.keras.layers.Activation('elu'))\n", "model.add(tf.keras.layers.Dropout(0.25))\n", "\n", "model.add(tf.keras.layers.Dense(3))\n", "model.add(tf.keras.layers.Activation('softmax'))\n", "\n", "model.summary()"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "xLeZATVaNAnE"}, "source": ["## Train on the TPU\n", "\n", "To begin training, construct the model on the TPU and then compile it.\n", "\n", "The following code demonstrates the use of a generator function and `fit_generator` to train the model.  Alternately, you can pass in `x_train` and `y_train` to `tpu_model.fit()`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 734}, "colab_type": "code", "id": "pWEYmd_hIWg8", "outputId": "31a570c8-872c-4ff6-abb9-e1cf62c92501"}, "outputs": [], "source": ["import os\n", "\n", "model.compile(\n", "    optimizer=\"Adam\",\n", "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n", "    metrics=['sparse_categorical_accuracy']\n", ")\n", "\n", "def train_gen():\n", "    \"\"\"Training, no batches.\n", "    \"\"\"\n", "    while True:\n", "        yield X_train, y_train"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.fit(\n", "    X_train, y_train,\n", "    epochs=32,\n", "    batch_size=50,\n", "    validation_data=(X_val, y_val),\n", "    validation_freq=32,\n", ")"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "ESL6ltQTMm05"}, "source": ["## Check the results (inference)\n", "\n", "Now that you are done training, see how well the model can predict fossil types."]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 833}, "colab_type": "code", "id": "SaYPv_aKId2d", "outputId": "a7479907-c7d0-4786-81f4-18286f93adf4"}, "outputs": [], "source": ["LABEL_NAMES = ['ammonites', 'fish', 'trilobites']\n", "\n", "y_pred = model.predict(X_val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {}, "colab_type": "code", "id": "LJSlWUxQiR-f"}, "outputs": [], "source": ["%matplotlib inline\n", "from matplotlib import pyplot\n", "\n", "import random\n", "\n", "def visualize(X_val, y_val, y_prob, cutoff=0.5, ncols=6, nrows=3, figsize=(12, 8), classes=None, shape=None):\n", "    \"\"\"\n", "    Visualize some random samples from the prediction results.\n", "    Colours: green for a good prediction, red for a wrong one. If the\n", "    probability was less than some cutoff (default 0.5), we'll mute the colour.\n", "\n", "    Args:\n", "        X_val (ndarray): The validation features, n_samples x n_features.\n", "        y_val (ndarray): The validation labels, n_samples x 1.\n", "        y_prob (ndarray): The predicted probabilities, n_samples x n_classes.\n", "        cutoff (float): the cutoff for 'uncertain'.\n", "        ncols (int): how many plots across the grid.\n", "        nrows (int): how many plots down the grid.\n", "        figsize (tuple): tuple of ints.\n", "        classes (array-like): the classes, in order. Will be inferred if None.\n", "        shape (tuple): Shape of each instance, if it needs reshaping.\n", "    \"\"\"\n", "    idx = random.sample(range(X_val.shape[0]), ncols*nrows)\n", "    sample = X_val[idx]\n", "\n", "    if classes is None:\n", "        classes = np.unique(y_val)\n", "    else:\n", "        y_val = np.asarray(classes)[y_val]\n", "\n", "    fig, axs = plt.subplots(figsize=figsize, ncols=ncols, nrows=nrows)\n", "    axs = axs.ravel()\n", "\n", "    for ax, img, actual, probs in zip(axs, sample, y_val[idx], y_prob[idx]):\n", "\n", "        pred = classes[np.argmax(probs)]\n", "        prob = np.max(probs)\n", "        if shape is not None:\n", "            img = img.reshape(shape)\n", "\n", "        ax.imshow(np.squeeze(img), cmap='gray')\n", "        ax.set_title(f\"{pred} - {prob:.3f}\\n[{actual}]\")\n", "        ax.set_xticks([])\n", "        ax.set_yticks([])\n", "\n", "        if prob > cutoff:\n", "            c = 'limegreen' if (actual == pred) else 'red'\n", "        else:\n", "            c = 'y' if (actual == pred) else 'lightsalmon'\n", "\n", "        for spine in ax.spines.values():\n", "            spine.set_edgecolor(c)\n", "            spine.set_linewidth(4)\n", "\n", "    return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["visualize(X_val, y_val, y_pred, classes=LABEL_NAMES)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Incorrectly classified only.\n", "wrong_idx = np.argmax(y_pred, axis=-1) != y_val\n", "y_pred_ = y_pred[wrong_idx]\n", "y_val_ = y_val[wrong_idx]\n", "X_val_ = X_val[wrong_idx]\n", "\n", "visualize(X_val_, y_val_, y_pred_, classes=LABEL_NAMES)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"accelerator": "TPU", "colab": {"collapsed_sections": [], "name": "0_Image_classification_on_the_cloud", "provenance": [], "toc_visible": true, "version": "0.3.2"}, "kernelspec": {"display_name": "geocomp-ml", "language": "python", "name": "geocomp-ml"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.7"}}, "nbformat": 4, "nbformat_minor": 1}