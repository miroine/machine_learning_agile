{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Machine learning: regression\n", "\n", "We'll try to predict missing well logs using regression.\n", "\n", "The data are from Colorado. We've already loaded the data into a CSV."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "\n", "%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from ipywidgets import interact"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["well_logs = '../data/Colorado_well_data.csv'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(well_logs, index_col=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Look at the counts: some of the features have some NaNs. It looks like we won't lose too much data by doing a `dropna`..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.dropna()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["I'd prefer it if the well names were integers not floats."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.Well = df.Well.astype(int)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Visual inspection of the data space"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["well = 1\n", "\n", "features = ['CAL', 'SP', 'GR', 'RES', 'NPHI', 'RHOB']\n", "target = 'DT'\n", "\n", "fig, axs = plt.subplots(ncols=len(features)+1, sharey=True, figsize=(8,8))\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax.plot(df.loc[df.Well==well, feature], df.loc[df.Well==well, 'Depth'])\n", "    ax.set_title(feature)\n", "axs[-1].plot(df.loc[df.Well==well, target], df.loc[df.Well==well, 'Depth'], color='red')\n", "axs[-1].set_title(target)\n", "axs[-1].invert_yaxis()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=len(features), figsize=(15, 3))\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax = sns.distplot(df[feature], ax=ax)\n", "    ax.set_title(feature)\n", "    ax.set_yticks([])"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div class=\"alert alert-success\">\n", "Make a 'log<sub>10</sub> resisitivity' to deal with the usual RES distribution. Call it `LogRes`.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(df.LogRes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And update the `features` list:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features.remove('RES')\n", "features.append('LogRes')"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div class=\"alert alert-success\">\n", "Now look at the gamma ray. Are the very high values coming from one well or from lots of places? \n", "\n", "Decide how to fix the gamma ray. For example, you could:\n", "\n", "- Remove one or more wells with bad GR.\n", "- Remove only the rows with very high values.\n", "- Clip the GR, e.g. using `pd.Series.clip()`.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.Well[df.GR > 500].unique()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.GR[df.Well==18].plot()\n", "plt.axhline(400, c='red')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(df.GR)"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div class=\"alert alert-success\">\n", "What is causing the long tail in the NPHI data? Is it spikes or a bad log?\n", "\n", "Decide how best to fix the NPHI, limiting its range to the interval 0 to 0.5.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(df.NPHI)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The distributions should now look something like this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=len(features), figsize=(15, 3))\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax = sns.distplot(df[feature], ax=ax)\n", "    ax.set_title(feature)\n", "    ax.set_yticks([])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Split the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.Well.unique()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["How many wells is that?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["len(df.Well.unique())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's start by training on the first six wells only."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n = 8  # We'll come back and change this number."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_train = df[df.Well <= n].copy()\n", "df_val = df[(df.Well >= 70) & (df.Well < 85)].copy()   # 12 wells\n", "df_test = df[df.Well >= 85].copy()  # 10 wells"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features = ['GR', 'NPHI', 'RHOB', 'LogRes']\n", "target = 'DT'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Check the distributions\n", "\n", "We'd like to make sure the distributions of the 3 datasets are comparable."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=len(features), figsize=(15,3))\n", "\n", "for ax, feature in zip(axs, features):\n", "    sns.distplot(df_train[feature], ax=ax)\n", "    sns.distplot(df_val[feature], ax=ax)\n", "    sns.distplot(df_test[feature], ax=ax)\n", "    ax.set_yticklabels([])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Make `X` and `y`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = df_train[features].values\n", "y_train = df_train[target].values\n", "\n", "X_val = df_val[features].values\n", "y_val = df_val[target].values\n", "\n", "X_test = df_test[features].values\n", "y_test = df_test[target].values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Normalize"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "\n", "scaler = StandardScaler()\n", "\n", "scaler.fit(X_train)\n", "\n", "X_train = scaler.transform(X_train)\n", "X_val = scaler.transform(X_val)\n", "X_test = scaler.transform(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train a model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression, Lasso, Ridge\n", "\n", "regr = Ridge()\n", "\n", "regr.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_val['DT_pred_LR'] = regr.predict(X_val)\n", "\n", "df_val.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_track(df, idx, true, pred):\n", "    fig, ax = plt.subplots(1,1)\n", "    fig.set_size_inches(12,2)\n", "    true = df.loc[df.Well == idx, true]\n", "    pred = df.loc[df.Well == idx, pred]\n", "    depths = df.loc[df.Well == idx, 'Depth']\n", "    ax.plot(depths, true, 'k', lw=1.5)\n", "    ax.plot(depths, pred, 'r', lw=1.5)\n", "    ax.set_xlim(1300, 2400)\n", "    ax.set_ylim(40, 140)\n", "    return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@interact(idx=(df_val.Well.unique().min(), df_val.Well.unique().max(), 1))\n", "def plot_different_wells(idx):\n", "    plot_track(df_val, idx, 'DT', 'DT_pred_LR')\n", "    return\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Evaluation metrics\n", "\n", "Two convenient ways to evaluate regressions are with the $R^2$ score..."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import r2_score, mean_squared_error\n", "\n", "r2_score(df_val.DT, df_val.DT_pred_LR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And the RMS error:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.sqrt(mean_squared_error(df_val.DT, df_val.DT_pred_LR))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Check error distribution\n", "\n", "In particular, we want to check that:\n", "\n", "1. The errors are normally distributed with a zero mean.\n", "1. The variance of the errors is not correlated with the parameters.\n", "\n", "There's some good advice about normality tests in [this article by Jason Brownlee](https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/).\n", "\n", "First we'll just use visual inspection:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["residuals = df_val['DT_pred_LR'] - df_val['DT']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.distplot(residuals)\n", "plt.axvline(0, color='k', lw=0.5)\n", "plt.axvline(residuals.mean(), color='r')\n", "plt.grid(color='k', alpha=0.15)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Normality: QQ plot\n", "\n", "A quantile-quantile plot generates an idealized distribution, in this case a Gaussian. The idealized samples are divided into quantiles, then each data point in the sample is paired with a similar member from the idealized distribution. The line `'s'` represents the standard 'normal' distribution."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from statsmodels.graphics.gofplots import qqplot\n", "\n", "qqplot(residuals, line='s')\n", "plt.axvline(0, color='k', lw=0.5)\n", "plt.axhline(0, color='k', lw=0.5)\n", "plt.grid(color='k', alpha=0.15)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Normality: Shapiro&ndash;Wilk test\n", "\n", "Not convinced about this &mdash; seems like most large samples don't fit. `p` just gets very small."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy.stats import shapiro\n", "\n", "res_shuf = residuals.values\n", "np.random.shuffle(res_shuf)\n", "\n", "stat, p = shapiro(res_shuf[:500])\n", "print(f'Statistics = {stat:.3f}, p = {p:.3f}')\n", "\n", "alpha = 0.05\n", "if p > alpha:\n", "    print('Sample looks Gaussian (fail to reject H0)')\n", "else:\n", "    print('Sample does not look Gaussian (reject H0)')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Homoscedasticity: visual inspection\n", "\n", "We want to check that the variance of the errors is not correlated with our parameters.\n", "\n", "If they are correlated (if the plots below show points with narrow spread at one end and wide at the other), then there are nonlinearities in the data that are not captured by the model. It could be that outliers are skewing the distribution."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axs = plt.subplots(ncols=len(features), figsize=(16,4), sharey=True)\n", "\n", "for ax, feature in zip(axs, features):\n", "    ax.scatter(df_val[feature], residuals, s=1, alpha=0.1)\n", "    ax.set_xlabel(feature)\n", "    ax.axhline(0, color='k', lw=0.5)\n", "    ax.grid(color='k', alpha=0.15)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Seems like there could be an issue in shales (low NPHI), and in rocks with low HC saturation."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Coefficients\n", "\n", "**If the features have been standardized**, then we can interpret the learned coefficients (or parameters, or weights if you prefer) as feature importance."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.set_printoptions(suppress=True)\n", "regr.coef_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regr.intercept_"]}, {"cell_type": "markdown", "metadata": {"tags": ["exercise"]}, "source": ["<div class=\"alert alert-success\">\n", "Can you make a list of the features ordered by their coefficients?", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['InvGardner'] = 108 * df.RHOB**4"]}], "metadata": {"kernelspec": {"display_name": "geocomp-ml", "language": "python", "name": "geocomp-ml"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.7"}}, "nbformat": 4, "nbformat_minor": 2}